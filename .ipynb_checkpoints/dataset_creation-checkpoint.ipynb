{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428ad6a9-a8a1-4d24-9cd3-edd83d918372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1148e1e-8480-4721-b57b-35bda4ad657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"D:\\\\DataSet\"\n",
    "files = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9e0398c-9633-4399-9f9e-7fb6e848ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = []\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "472cb82a-2038-4707-af1f-45aad58fa86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV created\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    pdf_path = os.path.join(folder, file)\n",
    "    text = \"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + \"\\n\"\n",
    "    doc.close()\n",
    "    resumes.append(text.strip())\n",
    "\n",
    "df = pd.DataFrame({\"resume_text\" : resumes})\n",
    "df.to_csv(\"resume_dataset.csv\", index = False, encoding= \"utf-8\")\n",
    "\n",
    "print(\"CSV created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91702380-1309-4ee6-b2e6-19aca5cf6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"resume_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10ab0f3-187c-4530-ad97-ea769597b09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abhishek Chaudhary \\n   ac5712916@gmail.com  |...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         resume_text\n",
       "0  Abhishek Chaudhary \\n   ac5712916@gmail.com  |..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9301477b-52fa-4940-92aa-3ac3b74c7d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "098979aa-101a-4aeb-8d91-fb4f9a3a22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job1 = \"\"\"Embark on a transformative journey as a Data Analyst at Barclays, where you'll spearhead the evolution of our digital landscape, driving innovation and excellence. You'll harness cutting-edge technology to revolutionize our digital offerings, ensuring unparalleled customer experiences.\n",
    "This role is within the Data Curation and Engagement team, which is responsible for the delivery and development of business, regulatory and Client reporting across Barclaycard Payments. The role will involve engaging with stakeholders from across the business, to carry out requirement analysis, data discovery and prototyping to assist in leveraging available data and in the development of reporting and analytical solutions to satisfy business use case needs and ensuring the continuity of reporting following source systems and platform changes. The roles holder will be required to drive best practice in data solutions, demonstrate strong data governance principles and be seeking to continually drive process improvements.\n",
    "To be a successful Data Analyst you should have experience with:\n",
    "Accountable to the Head of Data Curation and Engagement to provide support to the data delivery.\n",
    "Engage with the required stakeholders to analyse requirements, undertake data discovery and prototype business rules to fastrack subsequent data solution delivery / automate data movement and processing.\n",
    "Maintain documentation of data reporting controls and processes for compliance.\n",
    "Empowered to optimise and improve data processes.\n",
    "Application of advanced data analytical techniques to solve complex business problems. \n",
    "Designing and prototyping Solutions for data transformation and data cleansing to prepare data for analysis.\n",
    "Some Other Highly Valued Skills May Include\n",
    "Experience of working with a range of stakeholders and building effective relationships across the business and geographies.\n",
    "Strong knowledge of SAS, Databricks and SQL.\n",
    "Excellent communication and stakeholder management skills.\n",
    "Ability to articulate technical findings in business terms and demonstrate value to stakeholders.\n",
    "\"\"\"\n",
    "job2 = \"\"\"\n",
    "As a Full Stack Engineer at Prime Corporate, you will play a critical role in building and optimizing our AI-powered Edtech platforms and multi-agent system interfaces. You will work across the technology stack—from backend logic and APIs to intuitive, high-performance frontends—ensuring seamless integration of intelligent agents into our products. This is a high-impact role for a driven engineer who thrives in fast-paced, innovation-led environments and is eager to work on next-generation AI systems.\n",
    "Key Responsibilities\n",
    "Design, develop, and maintain scalable, secure, and high-performance web applications.\n",
    "Build APIs and backend services to support intelligent agent workflows and Edtech functionalities.\n",
    "Collaborate with AI researchers, product managers, and UI/UX designers to deliver intuitive user experiences.\n",
    "Implement real-time data visualization, reporting dashboards, and interactive interfaces.\n",
    "Integrate third-party services, APIs, and AI/ML models into platform features.\n",
    "Optimize application performance, security, and scalability.\n",
    "Participate in code reviews, testing, debugging, and deployment.\n",
    "Document technical designs, architecture decisions, and development processes.\n",
    "Stay updated with emerging tools, frameworks, and AI-powered development trends.\n",
    "What We Are Looking For\n",
    "Strong proficiency in JavaScript/TypeScript, React.js (or similar frontend frameworks), and Node.js (or similar backend frameworks).\n",
    "Solid understanding of RESTful APIs and database systems (SQL/NoSQL).\n",
    "Experience with Git, Docker, and cloud platforms (AWS, GCP, or Azure).\n",
    "Basic knowledge of AI/ML concepts, LLM integration, and API-based AI tools is a plus.\n",
    "Strong problem-solving skills and a passion for building innovative, user-centric products.\n",
    "Self-motivated and able to work in a fast-paced startup environment.\n",
    "No formal degree required—skills, projects, and passion matter most.\n",
    "\"\"\"\n",
    "job3 = \"\"\" Job Summary:  The role plays a Plays a crucial role in helping businesses make informed decisions by leveraging data & Advanced AI Solutions & will collaborate with stakeholders, design data models, create algorithms, and share\n",
    "\n",
    "meaningful insights to drive business success\n",
    "\n",
    "Key Responsibilities- Data & Analytics\n",
    "\n",
    " Work with supply chain, manufacturing manager, warehouse managers, customer account managers and quality function to produce manufacturing schedules, solutions to improve existing processes\n",
    " Gathering and interpreting data from various sources.\n",
    " Cleaning and verifying the accuracy of data sets to ensure data integrity.\n",
    " Build and maintain data pipelines for collecting, preprocessing, and integrating diverse data sources for comprehensive analysis and actionable insights.\n",
    " Developing and implementing data collection systems and strategies to optimize efficiency and accuracy.\n",
    " Applying statistical techniques to analyse and interpret complex data sets.\n",
    " Develop and implement statistical models for predictive analysis.\n",
    " Build and deploy machine learning models to solve business problems.\n",
    " Creating visual representations of data through charts, graphs, and dashboards to communicate findings effectively.\n",
    " Develop dashboards and reports for ongoing monitoring and analysis.\n",
    " Create, modify and improve complex manufacturing schedule.\n",
    " Create scenario planning model for manufacturing.\n",
    " Develop manufacturing schedule adherence probability model.\n",
    " Regularly monitoring and evaluating data quality, making recommendations for improvements as necessary.\n",
    " Staying up-to-date with industry trends and best practices in data analysis and reporting.\n",
    " Ensuring compliance with data privacy and security regulations.\n",
    "\n",
    "\n",
    "Key Responsibilities- AI\n",
    "\n",
    " End-to-End AI Solution Development \n",
    "\n",
    " Data Engineering: Independently develop data pipelines, perform data extraction, transformation,\n",
    "\n",
    "\n",
    "and loading (ETL) for AI model consumption.\n",
    "\n",
    " Model Integration : Integrate foundational models and retrieval-augmented generation (RAG)\n",
    "\n",
    "\n",
    "techniques\n",
    "\n",
    " Backend Development: Implement backend services and API endpoints to support AI solutions.\n",
    " Frontend Integration : Develop or adapt frontend interfaces for user interaction.\n",
    "\n",
    "\n",
    " Innovation & Self-Development \n",
    "\n",
    " Continuous Learning: Stay current on foundational AI models, RAG techniques\n",
    " Ownership & Autonomy : Take full ownership of assigned use cases, handling all aspects of\n",
    "\n",
    "\n",
    "development, testing, and deployment with minimal supervision\n",
    "\n",
    " Person Profile. \n",
    "\n",
    " Qualification-  B. Tech- CSE,ECE.\n",
    "\n",
    " Experience  -  3-5 years of relevant experience in preferably Pharma/Chemical/Manufacturing Industry.\n",
    "\n",
    "Technical Skills - Preferred\n",
    "\n",
    " P rogramming : Proficiency in Python for data handling and AI-related scripting.\n",
    " Data Engineering: Familiarity with data pipeline development, ETL processes, and data preprocessing techniques.\n",
    " Testing and QA : Knowledge of testing frameworks and tools to ensure model robustness, as well as\n",
    "\n",
    "\n",
    "experience with automated testing for QA processes.\n",
    "\n",
    "Other Skills- Preferred\n",
    "\n",
    " Experience with RAG : Familiarity with Retrieval-Augmented Generation techniques and their applications.\n",
    " Prompt Engineering : Knowledge of prompt engineering techniques to optimize generative AI\n",
    "\n",
    "models for specific tasks and enhance output relevance.\n",
    "\n",
    " Predictive Modelling : Experience in predictive modeling areas, such as traditional supervised and unsupervised learning,\n",
    " Advanced AI Concepts : Basic familiarity with foundational generative AI models and Natural Language Processing (NLP).\n",
    " Experience with big data technologies (e.g., Hadoop, Spark).\n",
    " Knowledge of cloud platforms (e.g., AWS, Azure, Google Cloud).\n",
    " Strong analytical and problem-solving skills with the ability to handle complex data sets.\n",
    " Excellent attention to detail and a high level of accuracy in data analysis.\n",
    " Solid knowledge of data visualization techniques and experience using visualization tools like Tableau or Power BI.\n",
    " Strong communication skills to present findings and insights to non-technical stakeholders effectively\n",
    " Ability to work collaboratively in a team environment and adapt to changing priorities.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b782d491-9101-428c-90b8-11975b0f0ee7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m jobs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mjob2\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'job2' is not defined"
     ]
    }
   ],
   "source": [
    "jobs.append(job2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad410439-127d-43c3-b4bd-c908fea6ebc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Embark on a transformative journey as a Data Analyst at Barclays, where you'll spearhead the evolution of our digital landscape, driving innovation and excellence. You'll harness cutting-edge technology to revolutionize our digital offerings, ensuring unparalleled customer experiences.\\n\\nThis role is within the Data Curation and Engagement team, which is responsible for the delivery and development of business, regulatory and Client reporting across Barclaycard Payments. The role will involve engaging with stakeholders from across the business, to carry out requirement analysis, data discovery and prototyping to assist in leveraging available data and in the development of reporting and analytical solutions to satisfy business use case needs and ensuring the continuity of reporting following source systems and platform changes. The roles holder will be required to drive best practice in data solutions, demonstrate strong data governance principles and be seeking to continually drive process improvements.\\n\\nTo be a successful Data Analyst you should have experience with:\\n\\n\\nAccountable to the Head of Data Curation and Engagement to provide support to the data delivery.\\nEngage with the required stakeholders to analyse requirements, undertake data discovery and prototype business rules to fastrack subsequent data solution delivery / automate data movement and processing.\\nMaintain documentation of data reporting controls and processes for compliance.\\nEmpowered to optimise and improve data processes.\\nApplication of advanced data analytical techniques to solve complex business problems. \\nDesigning and prototyping Solutions for data transformation and data cleansing to prepare data for analysis.\\n\\n\\nSome Other Highly Valued Skills May Include\\n\\n\\nExperience of working with a range of stakeholders and building effective relationships across the business and geographies.\\nStrong knowledge of SAS, Databricks and SQL.\\nExcellent communication and stakeholder management skills.\\nAbility to articulate technical findings in business terms and demonstrate value to stakeholders.\\n\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326cb402-9f2c-4c71-9483-c83d68de805d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
